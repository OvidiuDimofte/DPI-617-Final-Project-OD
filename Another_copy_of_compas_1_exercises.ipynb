{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OvidiuDimofte/DPI-617-Final-Project-OD/blob/main/Another_copy_of_compas_1_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Law, Order, and Algorithms**\n",
        "# Algorithmic fairness — Part 1 of 2\n",
        "\n",
        "In this lab, we'll build a risk assessment algorithmic to inform pretrial detention decisions, and examine its accuracy and equity.\n",
        "\n",
        "This exercise is predicated on the assumption that it is acceptable to detain (at least some) individuals pretrial.\n",
        "Many, though, argue that (nearly) all defendants should be released on their own recognizance, in part because they have not yet been convicted of a crime. Further, even modest bail requirements can impose disproportionate burdens on the most vulnerable members of society. Some jurisdictions have taken steps toward reforming the pretrial processs — including [ending cash bail](https://www.npr.org/2021/02/22/970378490/illinois-becomes-first-state-to-eliminate-cash-bail) — though pretrial detention is still the norm rather than the exception."
      ],
      "metadata": {
        "id": "lb6ujqFPhL7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting started**\n",
        "\n",
        "Before you start, create a copy of this Jupyter notebook in your own Google Drive by clicking `Copy to Drive` in the menubar. If you do not do this your work will not be saved!\n",
        "\n",
        "Remember to save your work frequently by pressing command-S or clicking File > Save in the menubar.\n",
        "\n",
        "We recommend completing this problem set in Google Chrome."
      ],
      "metadata": {
        "id": "IVvkibYxhl0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to load the `tidyverse` library and set some formatting options."
      ],
      "metadata": {
        "id": "D4J4hTwHh1xN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYxxqMkJeNkY"
      },
      "outputs": [],
      "source": [
        "# Some initial setup\n",
        "\n",
        "# load libraries\n",
        "library(tidyverse)\n",
        "\n",
        "# Set some formatting options\n",
        "options(digits = 3,\n",
        "  repr.matrix.max.rows = 10,\n",
        "  repr.matrix.max.cols = 100,\n",
        "  repr.plot.width = 8,\n",
        "  repr.plot.height = 6)\n",
        "theme_set(theme_bw())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F1c_B9qeNkW"
      },
      "source": [
        "## Background\n",
        "\n",
        "In 2016, ProPublica published a [now-famous article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) analyzing and criticizing the lack of fairness in a risk assessment tool used nationwide called COMPAS. Here, we will take a look at a cleaned-up version of the COMPAS data that ProPublica used, and try to better understand algorithmic fairness by investigating the claims ProPublica made, along with the [counterclaims](https://www.propublica.org/article/technical-response-to-northpointe) made by Northpointe (now re-branded as [Equivant](https://www.equivant.com/)).\n",
        "\n",
        "While Northpointe notes that their algorithm does not use race information and that their model is _calibrated_ across racial groups, ProPublica points out that the COMPAS scores differ in false positive rates across racial groups (violating error-rate parity) and result in detaining relatively more Black defendants than white defendants. In this notebook, we will examine some of their claims by building and evaluating our own risk assessment tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGiaVivteNka"
      },
      "source": [
        "## COMPAS data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be working with publicly available COMPAS data collected and released by ProPublica. Run the cell below to load the data."
      ],
      "metadata": {
        "id": "5JEOGdCiitr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnslzU3zeNkb"
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "fname <- \"https://github.com/5harad/DPI-617/blob/main/data/compas.rds?raw=true\"\n",
        "compas_df <- readRDS(url(fname))\n",
        "\n",
        "head(compas_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYH8iMmWeNka"
      },
      "source": [
        "A cleaned version of the COMPAS data is loaded as `compas_df`, with the following columns\n",
        "\n",
        "* `id`: unique identifiers for each case\n",
        "* `sex`, `dob`, `age`, `race`: demographic information for each defendant\n",
        "* `recid_score`, `violence_score`: COMPAS scores assessing risk that a defendant will recidivate (`violence_score` for violent crimes) within two years of release (higher scores correspond to higher risk)\n",
        "* `priors_count`: number of prior arrests\n",
        "* `is_recid`, `is_violent_recid`: Indicator variable that is `1` if the defendant was arrested for a new (violent) crime within two years of release, and `0` otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBY4UQ2AeNkb"
      },
      "source": [
        "### Exercise 1: Build a risk assessment model for recidivism\n",
        "\n",
        "We start by building our own risk assessment tool using only prior arrests (`priors_count`) and age (`age`) to predict whether a defendant will recidivate within two years of release (`is_recid`).\n",
        "First, fit a model to estimate the probability of this outcome for each defendant.\n",
        "We will call this model `recid_model`.\n",
        "\n",
        "Hint: Remember that the general syntax for fitting a regression model is `lm(OUTCOME ~ FACTOR1 + FACTOR1, data = DATA)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj8Gyqp_eNkb"
      },
      "outputs": [],
      "source": [
        "# Build a regression model estimating recidivism probability\n",
        "\n",
        "recid_model <-\n",
        "# WRITE CODE HERE\n",
        "\n",
        "# Fit the logistic regression model\n",
        "lm(is_recid ~ priors_count + age, data=compas_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to inspect your fitted model. How do you interpret the results?"
      ],
      "metadata": {
        "id": "QfM_j2yV_NFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(recid_model)"
      ],
      "metadata": {
        "id": "9gOQEoKc_TRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boSL6hcyeNkc"
      },
      "source": [
        "Run the code below to generate recidivism predictions, based on your model above. In addition to the raw probability estimates, we'll bin the risk scores into risk deciles, similar to COMPAS scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOZinsYpeNkc"
      },
      "outputs": [],
      "source": [
        "# Now we'll generate predictions for everyone in our dataset\n",
        "compas_df <- compas_df %>%\n",
        "    mutate(\n",
        "      risk = predict(recid_model),\n",
        "      risk_level = ntile(risk, 10)\n",
        "    )\n",
        "\n",
        "head(compas_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Ym2hj6eNkd"
      },
      "source": [
        "### Exercise 2: Calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjBc5oOaeNkd"
      },
      "source": [
        "Northpointe argued in part that its model was _fair_ because it was generally _well-calibrated_ across different race groups (i.e., for people who received similar risk scores, the actual rate of recidivism was similar across race groups).\n",
        "\n",
        "Check the calibration of your model by computing the empirical `recidivism_rate` (based on `is_recid`) for each risk level and race group. In the end you should have a data frame with three columns:\n",
        "`race`, `risk_level`, and `recidivism_rate`.\n",
        "\n",
        "Hint: first use `group_by` and then use `summarize`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EshH7xefeNkd"
      },
      "outputs": [],
      "source": [
        "calibration_by_race <- compas_df %>%\n",
        "# WRITE CODE HERE\n",
        "\n",
        "    group_by(race, risk_level) %>%\n",
        "    summarize(recidivism_rate = mean(is_recid))\n",
        "\n",
        "  calibration_by_race\n",
        "  print(calibration_by_race, n=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfHJCgafeNke"
      },
      "source": [
        "We can visualize model calibration by plotting the risk score bins with their corresponding emprical recidivism rate, using the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY_GLW2ueNke"
      },
      "outputs": [],
      "source": [
        "# Calibration plot\n",
        "ggplot(calibration_by_race,\n",
        "       aes(x = risk_level, y = recidivism_rate, color = race)) +\n",
        "    geom_line() + geom_point() +\n",
        "    scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1)) +\n",
        "    scale_x_continuous(breaks = 1:10) +\n",
        "    labs(x = \"\\nRisk level\",\n",
        "         y = \"Recidivism rate\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIcMnLYueNke"
      },
      "source": [
        "How do you interpret the plot above? Do you think it's important for the model to be calibrated? What if the model weren't calibrated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UfG5PfVeNkf"
      },
      "source": [
        "### Exercise 3: Disparities in detention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETBc66z6eNkf"
      },
      "source": [
        "Part of the objection to COMPAS is that Black defendents are more likely to be detained that white defendents.\n",
        "\n",
        "Examine detention rates by first selecting a detention threshold, and then computing the proportion of people above that threshold in each race group.\n",
        "\n",
        "Hint: To compute detention rates, first compute a new column (using `mutate`) that indicates whether an individual is above the detention threshold. Then `group_by` `race` and `summarize`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IEPa77GeNkf"
      },
      "outputs": [],
      "source": [
        "# Calculate detention rate by race\n",
        "\n",
        "# With a detention threshold of 6, approximately half\n",
        "# of individuals are detained\n",
        "detention_threshold = 6\n",
        "\n",
        "# WRITE CODE HERE\n",
        "compas_df %>%\n",
        "    mutate(detained = risk_level >= detention_threshold) %>%\n",
        "    group_by(race) %>%\n",
        "    summarize(\n",
        "        detention_rate = mean(detained)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFh0E7eveNkf"
      },
      "source": [
        "Run the cell below to help you visualize detention rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5DCwi4FeNkg"
      },
      "outputs": [],
      "source": [
        "# Plot the risk distribution\n",
        "options(repr.plot.width = 12, repr.plot.height = 6)\n",
        "\n",
        "compas_df %>%\n",
        "  count(race, risk_level) %>%\n",
        "  group_by(race) %>%\n",
        "  mutate(p = n/sum(n)) %>%\n",
        "  ungroup() %>%\n",
        "ggplot() +\n",
        "    geom_col(aes(x = risk_level, y = p)) +\n",
        "    scale_x_continuous(\"Risk level\", breaks = 1:10) +\n",
        "    scale_y_continuous(element_blank(), labels=scales::percent_format()) +\n",
        "    geom_vline(xintercept=detention_threshold-0.5, color='red', size=2) +\n",
        "    facet_wrap(~race)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5odY6CzeNkg"
      },
      "source": [
        "What do you think of the results above? Do you think differences in detention rates are a reasonable measure of your risk assessment algorithm's _fairness_? Do you think the algorithm leads to _disparate treatment_? What about _disparate impact_?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EntLf7eVeNkg"
      },
      "source": [
        "### Exercise 4: Equalizing detention rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAN4HnH1eNkg"
      },
      "source": [
        "After observing differences in the detention rates above, one might seek a policy that equalizes detention rates across race groups.\n",
        "\n",
        "In this exercise, set different thresholds for Black and white defendants to achieve comparable detention rates across groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtW55kUgeNkg"
      },
      "outputs": [],
      "source": [
        "# modify the detention thresholds below to equalize\n",
        "# detention rates across race groups.\n",
        "black_threshold = 8\n",
        "white_threshold = 6\n",
        "\n",
        "# Calculate detention rate by race\n",
        "compas_df %>%\n",
        "    mutate(detained = risk_level >= if_else(race == \"Caucasian\", white_threshold, black_threshold)) %>%\n",
        "    group_by(race) %>%\n",
        "    summarize(\n",
        "        detention_rate = mean(detained),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tfp2YbdeNkg"
      },
      "source": [
        "What are the threshold values that you find? Do you think this policy is more or less _fair_ than the single-threshold policy above? Does a multiple-threshold policy create disparate treatment? What about disparate impact?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}